---
title: "Project 4"
description: "R Project"
slug: "blog6"
image: R.jpg
keywords: ""
categories: 
    - ""
    - ""
date: 2017-10-31T22:42:51-05:00
draft: false
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(wbstats)
library(countrycode)
library(patchwork)
library(gganimate)
library(infer)
library(gganimate)
library(av)
library(tibble)
```

# Challenge 1: Excess rentals in TfL bike sharing

Recall the TfL data on how many bikes were hired every single day. We
can get the latest data by running the following

```{r, get_tfl_data, cache=TRUE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

We can easily create a facet grid that plots bikes hired by month and
year since 2015

```{r tfl_month_year_grid, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "tfl_distributions_monthly.png"), error = FALSE)
```

However, the challenge I want you to work on is to reproduce the
following two graphs.

```{r tfl_absolute_monthly_change, out.width="100%"}
knitr::include_graphics(here::here("images", "tfl_monthly.png"), error = FALSE)

# Calculate the average of monthly bikes hired from 2016 to 2019
avg_monthly_bikes_hired_2016_2019 <- bike %>% 
  filter(year >= 2016, year <= 2019) %>% 
  group_by(month) %>% 
  summarise(avg_monthly_bikes_hired_2016_2019 = sum(bikes_hired)/n())

# Calculate the average of monthly bikes hired from 2017
avg_monthly_bikes_hired_2017 <- bike %>% 
  filter(year >= 2017) %>% 
  group_by(year, month) %>% 
  summarise(avg_monthly_bikes_hired_2017 = sum(bikes_hired)/n())

# Merge the data so it's easier to plot it
final_data <- merge(avg_monthly_bikes_hired_2016_2019, avg_monthly_bikes_hired_2017, by = "month") %>% 
  mutate(diff = avg_monthly_bikes_hired_2017 - avg_monthly_bikes_hired_2016_2019)

# Each geom_line is for the averages, geom_ribbon is to shade the area enclosed between these lines.
ggplot(final_data, aes(x = month, group = year)) +
  geom_line(aes(y=avg_monthly_bikes_hired_2017)) +
  geom_line(aes(y=avg_monthly_bikes_hired_2016_2019), color = "blue", size = 1) + 
  geom_ribbon(aes( ymin = avg_monthly_bikes_hired_2017,
                   ymax = pmax(avg_monthly_bikes_hired_2016_2019, avg_monthly_bikes_hired_2017)), fill = "red", alpha=0.5) +
  geom_ribbon(aes( ymin = avg_monthly_bikes_hired_2016_2019,
                   ymax = pmax(avg_monthly_bikes_hired_2016_2019, avg_monthly_bikes_hired_2017)), fill = "green", alpha=0.5) +
  scale_fill_manual(values=c("red", "green"), name="fill") +
  facet_wrap(~year) +
  theme(legend.position="none") + 
  theme_minimal() +
  labs(title = "Montly changes in Tfl bike rentals",
       subtitle = "Change from montly average shown in blue and calculated between 2016-2019",
       x = NULL,
       y = "Bike rentals")
```


The second one looks at percentage changes from the expected level of
weekly rentals. The two grey shaded rectangles correspond to Q2 (weeks
14-26) and Q4 (weeks 40-52).

```{r tfl_percent_change_input, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "tfl_weekly.png"), error = FALSE)
```

```{r tfl_percent_change_output}
# Calculate the average of weekly bikes hired from 2016 to 2019
avg_weekly_bikes_hired_2016_2019 <- bike %>% 
  filter(year >= 2016, year <= 2019) %>% 
  group_by(week) %>% 
  summarise(avg_weekly_bikes_hired = sum(bikes_hired)/n())

# Calculate the percentage change in average weekly bikes hired from 2017 and clean the data by removing the 52nd week of 2022 data
avg_weekly_bikes_hired_2017 <- bike %>% 
  filter(year >= 2017) %>% 
  group_by(year, week) %>% 
  summarise(avg_weekly_bikes_hired = sum(bikes_hired)/n()) %>% 
  mutate(pct_change = 100*(avg_weekly_bikes_hired/avg_weekly_bikes_hired_2016_2019[week, 2] - 1)) %>% 
  filter(!(year == 2022 & week == 52))

# Plot the %change in the weekly bikes hired against each week
plot1 <- ggplot(avg_weekly_bikes_hired_2017, aes(x = week)) +
  geom_rect(aes(xmin = 14, xmax = 26, ymin = -Inf, ymax = Inf),
            alpha = 1/5, fill = "#e0e0e0") +
  geom_rect(aes(xmin = 40, xmax = 52, ymin = -Inf, ymax = Inf),
            alpha = 1/5, fill = "#e0e0e0") +
  geom_line(data = avg_weekly_bikes_hired_2017,
            mapping = aes(x = week,
                          y = pct_change$avg_weekly_bikes_hired)) +
  geom_ribbon(aes(x = week, 
                   ymin = pmin(pct_change$avg_weekly_bikes_hired, 0), 
                   ymax = pmin(pct_change$avg_weekly_bikes_hired,100)), fill = "green") +
  geom_ribbon(aes(x = week, 
                   ymin = pmax(pct_change$avg_weekly_bikes_hired, 0), 
                   ymax = pmin(pct_change$avg_weekly_bikes_hired,100)), fill = "red") +
  geom_rug(data = subset(avg_weekly_bikes_hired_2017, pct_change$avg_weekly_bikes_hired <= 0),
             aes(x = week, color = "green"), inherit.aes = F) +
  geom_rug(data = subset(avg_weekly_bikes_hired_2017, pct_change$avg_weekly_bikes_hired > 0),
             aes(x = week, color = "red"), inherit.aes = F) +
  facet_wrap(~year) +
  labs(title = "Weekly changes in Tfl bike rentals",
       subtitle = "% change from weekly averages calculated between 2016-2019",
       x = "week",
       y = NULL) +
  theme_minimal() +
  theme(legend.position = "none")
plot1
```

For both of these graphs, you have to calculate the expected number of
rentals per week or month between 2016-2019 and then, see how each
week/month of 2020-2022 compares to the expected rentals. Think of the
calculation `excess_rentals = actual_rentals - expected_rentals`.
```{r excess_rentals}
# Calculate the expected median monthly bikes hired
expected_monthly_bikes_hired_2016_2019 <- bike %>% 
  filter(year >= 2016, year <= 2019) %>% 
  group_by(month) %>% 
  summarise(expected_monthly_bikes_hired = mean(bikes_hired))

# Calculate the actual median monthly bikes hired
actual_monthly_bikes_hired_2020_22 <- bike %>% 
  filter(year >= 2020) %>% 
  group_by(year, month) %>% 
  summarise(actual_monthly_bikes_hired = mean(bikes_hired))

# Calculate the excess monthly bikes hired
excess_monthly_rentals_data <- merge(expected_monthly_bikes_hired_2016_2019, actual_monthly_bikes_hired_2020_22, by = "month") %>% 
  mutate(excess_monthly_rentals = actual_monthly_bikes_hired - expected_monthly_bikes_hired) %>% 
  arrange(year, month)

ggplot(excess_monthly_rentals_data, 
       aes(x = month, y = excess_monthly_rentals, group = year)) + 
  geom_line() + 
  facet_wrap(~year) + 
  labs(title = "Excess Monthly rentals from 2020-2022",
       x = "month",
       y = "Excess rentals")

# Calculate the expected median weekly bikes hired
expected_weekly_bikes_hired_2016_2019 <- bike %>% 
  filter(year >= 2016, year <= 2019) %>% 
  group_by(week) %>% 
  summarise(expected_weekly_bikes_hired = mean(bikes_hired))

# Calculate the actual weekly median bikes hired
actual_weekly_bikes_hired_2020_22 <- bike %>% 
  filter(year >= 2020) %>% 
  group_by(year, week) %>% 
  summarise(actual_weekly_bikes_hired = mean(bikes_hired)) %>%
  filter(!(year == 2022 & week == 52))

# Calculate the excess weekly bikes hired
excess_weekly_rentals_data <- merge(expected_weekly_bikes_hired_2016_2019, actual_weekly_bikes_hired_2020_22, by = "week") %>% 
  mutate(excess_weekly_rentals = actual_weekly_bikes_hired - expected_weekly_bikes_hired) %>% 
  arrange(year, week)

ggplot(excess_weekly_rentals_data, 
       aes(x = week, y = excess_weekly_rentals, group = year)) + 
  geom_line() + 
  facet_wrap(~year) + 
  labs(title = "Excess Weekly rentals from 2020-2022",
       x = "week",
       y = "Excess rentals")

```

Should you use the mean or the median to calculate your expected
rentals? Why?

As the data from 2016 to 2019 is uniform, mean can be used for the expected rentals calculation. But in presence of any outliers, as the year 2020, it's much more efficient to take median in the expected rentals.

In creating your plots, you may find these links useful:

-   <https://ggplot2.tidyverse.org/reference/geom_ribbon.html>
-   <https://ggplot2.tidyverse.org/reference/geom_tile.html>
-   <https://ggplot2.tidyverse.org/reference/geom_rug.html>

